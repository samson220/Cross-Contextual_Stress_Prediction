{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Randomized Search for LDA...\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import BayesianRidge, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read in data as pandas dataframe and display first 5 rows\n",
    "dataset = pd.read_csv('/Users/samsonmihirette/Documents/Final2/wesad2/wesad_all.csv')\n",
    "\n",
    "dataset['RMSSD'] = dataset['RMSSD'].fillna(0)\n",
    "dataset['SDSD'] = dataset['SDRR'].fillna(0)\n",
    "dataset['HR'] = dataset['HR'].fillna(0)\n",
    "dataset['pNN50'] = dataset['pNN50'].fillna(0)\n",
    "dataset['HF'] = dataset['HR'].fillna(0)\n",
    "dataset['HF_PCT'] = dataset['HF_PCT'].fillna(0)\n",
    "\n",
    "label_mapping = {\"baseline\": 0, \"meditation\": 1, \"amusement\": 2, \"stress\": 3}\n",
    "dataset['condition'] = dataset['condition'].replace(label_mapping)\n",
    "\n",
    "subCol = ['HR_SQRT','pNN25','MEAN_RR','HR','MEAN_RR_SQRT','MEAN_RR_LOG','MEDIAN_RR','LF_PCT', 'HF']\n",
    "\n",
    "dataset['condition'] = dataset['condition'].replace(label_mapping)\n",
    "y = dataset['condition'].copy()\n",
    "X = dataset[subCol]\n",
    "\n",
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['condition'] = df['condition'].replace(label_mapping)\n",
    "    y = df['condition'].copy()\n",
    "    X = df[subCol]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_inputs(dataset)\n",
    "\n",
    "\n",
    "# Define classifiers and their respective parameter grids for Randomized Search\n",
    "classifiers = {\n",
    "\n",
    "    # 'LR': (LogisticRegression(), {\n",
    "    #     'C': np.logspace(-4, 4, 20),  # Regularization parameter\n",
    "    #     'penalty': ['l1', 'l2'],  # Penalty ('l1' for Lasso, 'l2' for Ridge)\n",
    "    #     'solver': ['liblinear', 'saga']  # Optimization solver\n",
    "    # }),\n",
    "\n",
    "    'LDA': (LinearDiscriminantAnalysis(), {\n",
    "        'solver': ['lsqr', 'eigen'],  # Solvers compatible with shrinkage\n",
    "        'shrinkage': [None, 'auto', 0.1, 0.5, 0.9]  # Shrinkage parameter (if used)\n",
    "    }),\n",
    "    \n",
    "    # 'KNN': (KNeighborsClassifier(), {\n",
    "    #     'n_neighbors': [5, 10, 15],\n",
    "    #     'weights': ['uniform', 'distance'],\n",
    "    #     'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
    "    # }),\n",
    "\n",
    "    # 'CART': (DecisionTreeClassifier(), {\n",
    "    #     'max_depth': [None, 10, 20, 30, 40],\n",
    "    #     'min_samples_split': [2, 5, 10],\n",
    "    #     'min_samples_leaf': [1, 2, 4]          \n",
    "    # }),\n",
    "\n",
    "    # 'RF': (RandomForestClassifier(), {\n",
    "    #     'n_estimators': [100, 300, 500],\n",
    "    #     'max_features': ['sqrt', 'log2'],\n",
    "    #     'max_depth': [None, 10, 20, 30],\n",
    "    #     'min_samples_split': [2, 5, 10],\n",
    "    #     'min_samples_leaf': [1, 2, 4]\n",
    "    # }),\n",
    "\n",
    "    # 'GB': (GradientBoostingClassifier(), {\n",
    "    #     'n_estimators': [50, 100, 150],\n",
    "    #     'learning_rate': [0.01, 0.1, 0.2],\n",
    "    #     'max_depth': [3, 5, 7]\n",
    "    # }),\n",
    "\n",
    "    # 'SVM': (SVC(), {\n",
    "    #     'C': [0.1, 1, 10],\n",
    "    #     'gamma': ['scale', 'auto'],\n",
    "    #     'kernel': ['linear', 'rbf']\n",
    "    # }),\n",
    "\n",
    "    # 'abc': (AdaBoostClassifier(), {\n",
    "    #     'n_estimators': [50, 100, 200],\n",
    "    #     'learning_rate': [0.01, 0.1, 1.0]\n",
    "    # }),\n",
    "    # 'CB': (CatBoostClassifier(), {\n",
    "    #     'iterations': [100, 300, 500],\n",
    "    #     'learning_rate': [0.01, 0.1, 0.3],\n",
    "    #     'depth': [4, 6, 8],\n",
    "    #     'l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "    # }),\n",
    "\n",
    "    # 'XT': (ExtraTreesClassifier(), {\n",
    "    #         'n_estimators': [50, 100, 150],\n",
    "    #         'max_depth': [5, 10, 15, None]\n",
    "    # })\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Perform RandomizedSearchCV for each classifier\n",
    "for clf_name, (clf, param_grid) in classifiers.items():\n",
    "    print(f\"Running Randomized Search for {clf_name}...\")\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    clf_random_search = RandomizedSearchCV(clf, param_distributions=param_grid, n_iter=10, cv=kf, scoring='f1_macro', random_state=42, n_jobs=-1)\n",
    "    clf_random_search.fit(X, y)\n",
    "    \n",
    "    # Store cross-validation results, estimators, and test scores separately for each classifier\n",
    "    clf_results = {\n",
    "        'cv_results': clf_random_search.cv_results_,\n",
    "        'best_estimator': clf_random_search.best_estimator_,\n",
    "        'test_score': clf_random_search.best_score_\n",
    "    }\n",
    "\n",
    "    # Save the results for each classifier\n",
    "    def save_obj(obj, name):\n",
    "        with open(name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    save_obj(clf_results, f'/Users/samsonmihirette/Documents/Final2/wesad2/results/{clf_name}_F2train_wesad_RS-10kf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv222",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
